{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distant-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys,os\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "informative-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comprehensive-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'C:\\\\Users\\\\Faith Bagire\\\\PycharmProjects\\\\pythonProject\\\\causal_impact\\\\modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "approved-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_data import read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "every-charm",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fcd410408019>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#select features only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'diagnosis'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'diagnosis'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#select features only\n",
    "x=data.drop(['id','diagnosis'],axis=1)\n",
    "y=data['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-talent",
   "metadata": {},
   "source": [
    "#### Feature Selection using Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-harvest",
   "metadata": {},
   "source": [
    "The simplest method for feature selection is correlation between independent variables. Most ML models perform well when they are trained on only important features and for our case, we have 30 exploratory features. Using correlation coefficients, we can assume that variables with high correlation are redundant t a model and remain with any (arbitrary) on among them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,7))\n",
    "_=sns.heatmap(x.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=x.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(i+1, corr.shape[0]):\n",
    "        if corr.iloc[i,j] >= 0.9:\n",
    "            if columns[j]:\n",
    "                columns[j] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected column\n",
    "cols_pass=x.columns[columns].to_list()\n",
    "cols_dropped_corr=x.columns[~columns].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-webmaster",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Number of selected cols: {}'.format(len(cols_pass)))\n",
    "cols_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-scene",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Number of removed cols: {}'.format(len(cols_dropped_corr)))\n",
    "cols_dropped_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dict=corr.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_col={}\n",
    "for col in corr.columns:\n",
    "    one_col=corr_dict[col]\n",
    "    high_col[col]=[y for y in one_col if one_col[y]>=0.9 and one_col[y]< 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-mechanism",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop keys with empty list (Not highly correlated with any other variable)\n",
    "high_col={k: v for k, v in high_col.items() if v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-daily",
   "metadata": {},
   "source": [
    "By removing columns which are highly correlated (>=0.9, which is very high correlation usualy), we remain with 20 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-chrome",
   "metadata": {},
   "source": [
    "#### Tree based feature selection and random forest classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new=x[cols_pass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data train 80 % and test 20 %\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-affiliate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def random_forest_fimportance(x_train,y_train):\n",
    "    clf_rf_5 = RandomForestClassifier()      \n",
    "    clr_rf_5 = clf_rf_5.fit(x_train,y_train)\n",
    "    importances = clr_rf_5.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(x_train.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "\n",
    "    plt.figure(1, figsize=(14, 7))\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(x_train.shape[1]), importances[indices])\n",
    "    plt.xticks(range(x_train.shape[1]), x_train.columns[indices],rotation=90)\n",
    "    plt.xlim([-1, x_train.shape[1]])\n",
    "    plt.show()\n",
    "    \n",
    "    return clf_rf_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model1=random_forest_fimportance(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-brake",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(y_test,rf_model1.predict(x_test))\n",
    "print('Accuracy is: ',acc_score)\n",
    "confusion_mat = confusion_matrix(y_test,rf_model1.predict(x_test))\n",
    "_=sns.heatmap(confusion_mat,annot=True,fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x_new, y, test_size=0.2, random_state=423)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-series",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf_model2=random_forest_fimportance(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score1 = accuracy_score(y_test1,rf_model2.predict(x_test1))\n",
    "print('Accuracy is: {}'.format(acc_score1))\n",
    "confusion_mat1 = confusion_matrix(y_test1,rf_model2.predict(x_test1))\n",
    "_=sns.heatmap(confusion_mat1,annot=True,fmt=\"d\",cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-translation",
   "metadata": {},
   "source": [
    "By using confusion matrix accuracy score, we can see that the RF with 20 features actually has more accuracy that the model with 30 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-religion",
   "metadata": {},
   "source": [
    "### Stepwise forward elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_regression(X, y,\n",
    "                           threshold_out,\n",
    "                           verbose=False):\n",
    "    included=list(X.columns)\n",
    "    while True:\n",
    "        changed=False\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return pvalues,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_regression(X, y,\n",
    "                       threshold_in,\n",
    "                       verbose=False):\n",
    "    initial_list = []\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fwd=forward_regression(x,y,0.05,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pass_fwd=model_fwd.pvalues.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-cruise",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_values,model_bwd=backward_regression(x,y,0.6,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dropped_bwd=list(p_values.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(cols_dropped_bwd)&set(cols_dropped_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-binary",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "set(cols_pass)&set(cols_pass_fwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-cancer",
   "metadata": {},
   "source": [
    "Because with highly correlated variables, based on correlation method can pick any first variable\n",
    "among two or three that are highly correlated, then I have used a simple rule by making sure\n",
    "that variable that were removed by two methods (correlation& backward elimination) and those\n",
    "variables that were selected by two methods (correlation & forward selection) are considered.\n",
    "And then I can arbitrary select any one variable among highly correlated variables for those\n",
    "that are not agreed on by two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-webster",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x.columns.difference(set(cols_pass)&set(cols_pass_fwd) | set(cols_dropped_bwd)&set(cols_dropped_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-facing",
   "metadata": {},
   "source": [
    "#### Selecting the optimal columns \n",
    "*'area_se'* can be represented by *'radius_se'* \\\n",
    "\n",
    "*'texture_worst'* can be represented *'texture_mean'*\n",
    "\n",
    "*'compactness_worst', 'concave points_se','fractal_dimension_mean','fractal_dimension_se','smoothness_mean',\n",
    "'smoothness_worst','symmetry_mean','symmetry_se','texture_se'* are not correlated(>=0.9) with any other variable so they will be selected\\\n",
    "\n",
    "*'concave points_worst','concave points_mean','concavity_mean'*  I will select *'concave points_mean'*\\\n",
    "\n",
    "*'perimeter_worst','radius_mean', 'perimeter_mean', 'area_mean', 'radius_worst', 'area_worst'* are highly correlated, so i select *'radius_mean'* and *'radius_worst'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols=['compactness_worst','compactness_mean','compactness_se','concavity_se','concavity_worst',\n",
    "            'fractal_dimension_worst','radius_se','smoothness_se','symmetry_worst','concave points_mean',\n",
    "            'smoothness_mean','smoothness_worst','symmetry_mean','fractal_dimension_mean','radius_mean',\n",
    "            'radius_worst','symmetry_se','texture_se']"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
